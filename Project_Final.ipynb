{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE Equalization Function\n",
    "def clahe_equalization(image, clipLimit=1.1, tileGridSize=(8, 8)):\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    for i in range(image.shape[-1]):\n",
    "        image[..., i] = clahe.apply((image[..., i] * 255).astype(np.uint8)) / 255.0\n",
    "    return image\n",
    "\n",
    "# Preprocess Image Function\n",
    "def preprocess_image(image, brightness_correct=True, clipLimit=1.1, tileGridSize=(8, 8)):\n",
    "    image = image / (np.max(image) + 1e-8)\n",
    "    if brightness_correct:\n",
    "        image = clahe_equalization(image, clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    return image\n",
    "\n",
    "# Pads the image to have exactly 192 slices along the last axis.\n",
    "def pad_image_to_192_slices(image):\n",
    "    if image.shape[2] < 192:\n",
    "        padding_needed = 192 - image.shape[2]\n",
    "        image = np.pad(image, ((0, 0), (0, 0), (0, padding_needed)), mode='constant')\n",
    "    elif image.shape[2] > 192:\n",
    "        image = image[:, :, :192]\n",
    "    return image\n",
    "\n",
    "# Swap the axes to change from sagittal to axial\n",
    "def reorient_sagittal_to_axial(image):\n",
    "    image = np.swapaxes(image, 0, 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MRI Data Generator Class\n",
    "class MRI_DataGenerator(Sequence):\n",
    "    def __init__(self, list_IDs, batch_size=4, dim=(160, 160, 192), shuffle=True, augment=False, brightness_correct=True, clipLimit=2.0, tileGridSize=(8, 8)):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.brightness_correct = brightness_correct\n",
    "        self.clipLimit = clipLimit\n",
    "        self.tileGridSize = tileGridSize\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        X = self.__data_generation(list_IDs_temp)\n",
    "        return X, X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        X = np.empty((self.batch_size, self.dim[0], self.dim[1], 192, 1))\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            path = ID\n",
    "            try:\n",
    "                nii = nib.load(path)\n",
    "                image = nii.get_fdata()\n",
    "\n",
    "                # Reorient if the dataset is Healthy, MCI, or AD\n",
    "                if \"Healthy_sorted\" in path or \"MCI_sorted\" in path or \"AD_sorted\" in path:\n",
    "                    image = reorient_sagittal_to_axial(image)\n",
    "                    image = np.rot90(image, k=2, axes=(0, 1))  # Rotate 180 degrees anticlockwise\n",
    "                    image = image[:, :, ::-1]  # Reverse the slice order\n",
    "\n",
    "                # Preprocess, resize, and pad image\n",
    "                image = pad_image_to_192_slices(image)\n",
    "                resized_slices = [cv2.resize(image[:, :, slice_idx], (self.dim[0], self.dim[1])) for slice_idx in range(image.shape[2])]\n",
    "                image = np.stack(resized_slices, axis=-1)\n",
    "                image = preprocess_image(image, brightness_correct=self.brightness_correct, clipLimit=self.clipLimit, tileGridSize=self.tileGridSize)\n",
    "\n",
    "                if self.augment:\n",
    "                    image = self.__augment(image)\n",
    "                X[i, ..., 0] = image  # Adding the channel dimension\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {path}: {e}\")\n",
    "                X[i,] = np.zeros((self.dim[0], self.dim[1], 192, 1))\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "    def __augment(self, image):\n",
    "        if np.random.rand() < 0.5:\n",
    "            image = np.fliplr(image)\n",
    "        if np.random.rand() < 0.5:\n",
    "            image = np.flipud(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NIfTI Files from Folder\n",
    "def load_nii_files_from_folder(folder):\n",
    "    nii_files = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".nii\"):\n",
    "            nii_files.append(os.path.join(folder, filename))\n",
    "    return nii_files\n",
    "\n",
    "# Define paths to datasets\n",
    "healthy_path = 'CamCAN/CamCAN_subset'\n",
    "mci_path = 'ADNI/MCI_sorted'\n",
    "ad_path = 'ADNI/AD_sorted'\n",
    "\n",
    "# Load the data\n",
    "healthy_files = load_nii_files_from_folder(healthy_path)\n",
    "mci_files = load_nii_files_from_folder(mci_path)\n",
    "ad_files = load_nii_files_from_folder(ad_path)\n",
    "\n",
    "# Load training data\n",
    "folder_path = 'Human_Connectome'\n",
    "nii_files = load_nii_files_from_folder(folder_path)\n",
    "train_files, remaining_files = train_test_split(nii_files, test_size=0.2, random_state=42)\n",
    "val_files, test_files = train_test_split(remaining_files, test_size=0.5, random_state=42)\n",
    "\n",
    "# Load the test data from Human_Connectome\\vali_test for evaluation and visualization\n",
    "eval_test_files_path = 'Human_Connectome/vali_test'\n",
    "eval_test_files = load_nii_files_from_folder(eval_test_files_path)\n",
    "\n",
    "# Create data generators\n",
    "train_gen = MRI_DataGenerator(list_IDs=train_files, batch_size=4, dim=(160, 160, 192), shuffle=True, augment=True)\n",
    "val_gen = MRI_DataGenerator(list_IDs=val_files, batch_size=2, dim=(160, 160, 192), shuffle=False)\n",
    "test_gen = MRI_DataGenerator(list_IDs=test_files, batch_size=2, dim=(160, 160, 192), shuffle=False)\n",
    "eval_test_gen = MRI_DataGenerator(list_IDs=eval_test_files, batch_size=1, dim=(160, 160, 192), shuffle=False)\n",
    "healthy_gen = MRI_DataGenerator(list_IDs=healthy_files, batch_size=1, dim=(160, 160, 192), shuffle=False)\n",
    "mci_gen = MRI_DataGenerator(list_IDs=mci_files, batch_size=1, dim=(160, 160, 192), shuffle=False)\n",
    "ad_gen = MRI_DataGenerator(list_IDs=ad_files, batch_size=1, dim=(160, 160, 192), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the UNet model\n",
    "def unet_model(input_size=(160, 160, 192, 1)):\n",
    "    inputs = tf.keras.layers.Input(input_size)\n",
    "    c1 = tf.keras.layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "    p1 = tf.keras.layers.MaxPooling3D((2, 2, 2))(c1)\n",
    "    c2 = tf.keras.layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = tf.keras.layers.MaxPooling3D((2, 2, 2))(c2)\n",
    "    c3 = tf.keras.layers.Conv3D(256, (3, 3, 3), activation='relu', padding='same')(p2)\n",
    "    p3 = tf.keras.layers.MaxPooling3D((2, 2, 2))(c3)\n",
    "    c4 = tf.keras.layers.Conv3D(512, (3, 3, 3), activation='relu', padding='same')(p3)\n",
    "    p4 = tf.keras.layers.MaxPooling3D((2, 2, 2))(c4)\n",
    "    c5 = tf.keras.layers.Conv3D(1024, (3, 3, 3), activation='relu', padding='same')(p4)\n",
    "    \n",
    "    u6 = tf.keras.layers.Conv3DTranspose(512, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4], axis=-1)\n",
    "    c6 = tf.keras.layers.Conv3D(512, (3, 3, 3), activation='relu', padding='same')(u6)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv3DTranspose(256, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3], axis=-1)\n",
    "    c7 = tf.keras.layers.Conv3D(256, (3, 3, 3), activation='relu', padding='same')(u7)\n",
    "    \n",
    "    u8 = tf.keras.layers.Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c7)\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2], axis=-1)\n",
    "    c8 = tf.keras.layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same')(u8)\n",
    "    \n",
    "    u9 = tf.keras.layers.Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c8)\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1], axis=-1)\n",
    "    c9 = tf.keras.layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(u9)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv3D(1, (1, 1, 1), activation='sigmoid')(c9)\n",
    "    model = tf.keras.models.Model(inputs=[inputs], outputs=[outputs])  \n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "model = unet_model()\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (if available)\n",
    "try:\n",
    "    model = load_model('Saved_models/Trained_model.h5', compile=False)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mse'])\n",
    "except Exception as e:\n",
    "    print(f\"Error loading pre-trained model: {e}\")\n",
    "\n",
    "# Training setup\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=5,\n",
    "        callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
    "        verbose=2\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error during model training: {e}\")\n",
    "\n",
    "# Load the best model after training\n",
    "model.save('Saved_models/best_model.h5')\n",
    "model = load_model('Saved_models/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Saved_models/Trained_model.h5', compile=False)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of original and reconstructed images\n",
    "def visualize_reconstruction(generator, model, num_samples=2):\n",
    "    X, _ = generator[0]\n",
    "    actual_num_samples = min(num_samples, X.shape[0])\n",
    "    all_images = X[:actual_num_samples]\n",
    "    \n",
    "    reconstructed_imgs = []\n",
    "    for i in range(actual_num_samples):\n",
    "        image = np.expand_dims(all_images[i], axis=0)\n",
    "        reconstructed_img = model.predict(image)\n",
    "        reconstructed_imgs.append(reconstructed_img[0])\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(actual_num_samples):\n",
    "        ax = plt.subplot(2, actual_num_samples, i + 1)\n",
    "        middle_slice = all_images[i].shape[2] // 2\n",
    "        plt.imshow(all_images[i][:, :, middle_slice, 0], cmap='gray')\n",
    "        plt.title(f\"Original {i+1}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        ax = plt.subplot(2, actual_num_samples, i + 1 + actual_num_samples)\n",
    "        plt.imshow(reconstructed_imgs[i][:, :, middle_slice, 0], cmap='gray')\n",
    "        plt.title(f\"Reconstructed {i+1}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Visualize training data reconstruction\n",
    "print(\"Visualizing original and reconstructed images:\")\n",
    "visualize_reconstruction(val_gen, model, num_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reconstruction_error(model, images):\n",
    "    reconstructions = model.predict(images)\n",
    "    errors = np.mean(np.square(images - reconstructions), axis=(1, 2, 3, 4))\n",
    "    return errors\n",
    "\n",
    "# Evaluate and visualize slices\n",
    "def evaluate_and_visualize_slices(generator, subset_name, model, slice_indices=[30, 96, 162]):\n",
    "    mse_list = []\n",
    "    ssim_list = []\n",
    "    visualization_done = False  # Flag to ensure visualization happens only once\n",
    "\n",
    "    for i in range(len(generator)):\n",
    "        print(f\"Processing {subset_name} batch {i+1}/{len(generator)}...\")\n",
    "\n",
    "        # Get a batch of images\n",
    "        batch_images, _ = generator[i]\n",
    "\n",
    "        for j in range(batch_images.shape[0]):\n",
    "            sample_image = batch_images[j, ..., 0]  # Extract the image from the batch\n",
    "\n",
    "            # Predict the reconstructed image\n",
    "            sample_image_expanded = np.expand_dims(sample_image, axis=0)\n",
    "            sample_image_expanded = np.expand_dims(sample_image_expanded, axis=-1)\n",
    "            reconstructed_image = model.predict(sample_image_expanded)\n",
    "            reconstructed_image = reconstructed_image[0, :, :, :, 0]\n",
    "\n",
    "            mse = np.mean(np.square(sample_image - reconstructed_image))\n",
    "            ssim_value = np.mean([ssim(sample_image[:, :, slice_idx], reconstructed_image[:, :, slice_idx], data_range=sample_image.max() - sample_image.min()) for slice_idx in range(sample_image.shape[-1])])\n",
    "\n",
    "            mse_list.append(mse)\n",
    "            ssim_list.append(ssim_value)\n",
    "\n",
    "            # Visualize selected slices only once\n",
    "            if not visualization_done:\n",
    "                for slice_idx in slice_indices:\n",
    "                    plt.figure(figsize=(20, 5))\n",
    "\n",
    "                    plt.subplot(1, 4, 1)\n",
    "                    plt.title(f\"{subset_name} Original - Slice {slice_idx}\")\n",
    "                    plt.imshow(sample_image[:, :, slice_idx], cmap='gray')\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.subplot(1, 4, 2)\n",
    "                    plt.title(f\"{subset_name} Reconstructed - Slice {slice_idx}\")\n",
    "                    plt.imshow(reconstructed_image[:, :, slice_idx], cmap='gray')\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.subplot(1, 4, 3)\n",
    "                    plt.title(f\"{subset_name} Error (Original - Reconstructed) - Slice {slice_idx}\")\n",
    "                    error_image = np.abs(sample_image[:, :, slice_idx] - reconstructed_image[:, :, slice_idx])\n",
    "                    plt.imshow(error_image, cmap='jet')\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.subplot(1, 4, 4)\n",
    "                    plt.title(f\"{subset_name} Original with Error Heatmap - Slice {slice_idx}\")\n",
    "                    plt.imshow(sample_image[:, :, slice_idx], cmap='gray')\n",
    "                    plt.imshow(error_image, cmap='jet', alpha=0.6)\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.show()\n",
    "                \n",
    "                visualization_done = True  # Set the flag to True to prevent further visualization\n",
    "\n",
    "    print(f\"\\nAverage MSE for {subset_name}: {np.mean(mse_list)}\")\n",
    "    print(f\"Average SSIM for {subset_name}: {np.mean(ssim_list)}\")\n",
    "    return mse_list, ssim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and visualize reconstruction error and SSIM for the test data using the generator\n",
    "print(\"\\nEvaluating Test Data:\")\n",
    "test_mse, test_ssim = evaluate_and_visualize_slices(eval_test_gen, \"Test\", model)\n",
    "\n",
    "# Evaluate and visualize reconstruction error and SSIM for the Healthy, MCI, and AD datasets\n",
    "print(\"\\nEvaluating Healthy Data:\")\n",
    "healthy_mse, healthy_ssim = evaluate_and_visualize_slices(healthy_gen, \"Healthy\", model)\n",
    "\n",
    "print(\"\\nEvaluating MCI Data:\")\n",
    "mci_mse, mci_ssim = evaluate_and_visualize_slices(mci_gen, \"MCI\", model)\n",
    "\n",
    "print(\"\\nEvaluating AD Data:\")\n",
    "ad_mse, ad_ssim = evaluate_and_visualize_slices(ad_gen, \"AD\", model)\n",
    "\n",
    "# After evaluating, analyze the MSE and SSIM results\n",
    "print(\"\\nResults Summary:\")\n",
    "print(f\"Test Data - Average MSE: {np.mean(test_mse)}, Average SSIM: {np.mean(test_ssim)}\")\n",
    "print(f\"Healthy Data - Average MSE: {np.mean(healthy_mse)}, Average SSIM: {np.mean(healthy_ssim)}\")\n",
    "print(f\"MCI Data - Average MSE: {np.mean(mci_mse)}, Average SSIM: {np.mean(mci_ssim)}\")\n",
    "print(f\"AD Data - Average MSE: {np.mean(ad_mse)}, Average SSIM: {np.mean(ad_ssim)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_image_interactive_slice_viewer(images_dict, alpha=0.6, cmap='jet'):\n",
    "    \n",
    "    num_slices = list(images_dict.values())[0][0].shape[2]\n",
    "\n",
    "    # Slider to choose the slice index\n",
    "    slice_slider = widgets.IntSlider(min=0, max=num_slices-1, step=1, description='Slice:')\n",
    "    \n",
    "    # Checkbox to toggle the heatmap\n",
    "    heatmap_checkbox = widgets.Checkbox(value=True, description='Show Heatmap', disabled=False)\n",
    "    \n",
    "    def update_visualization(slice_index, show_heatmap):\n",
    "        plt.figure(figsize=(20, len(images_dict) * 5))\n",
    "        \n",
    "        for i, (label, (original_image, reconstructed_image)) in enumerate(images_dict.items()):\n",
    "            error_image = np.abs(original_image - reconstructed_image)\n",
    "            \n",
    "            original_slice = original_image[:, :, slice_index]\n",
    "            reconstructed_slice = reconstructed_image[:, :, slice_index]\n",
    "            error_slice = error_image[:, :, slice_index]\n",
    "            \n",
    "            error_slice_normalized = cv2.normalize(error_slice, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "            plt.subplot(len(images_dict), 4, i * 4 + 1)\n",
    "            plt.title(f\"{label} - Original Slice\")\n",
    "            plt.imshow(original_slice, cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(len(images_dict), 4, i * 4 + 2)\n",
    "            plt.title(f\"{label} - Reconstructed Slice\")\n",
    "            plt.imshow(reconstructed_slice, cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(len(images_dict), 4, i * 4 + 3)\n",
    "            plt.title(f\"{label} - Error (Original - Reconstructed)\")\n",
    "            plt.imshow(error_slice_normalized, cmap=cmap)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(len(images_dict), 4, i * 4 + 4)\n",
    "            plt.title(f\"{label} - Original with Error Heatmap\")\n",
    "            plt.imshow(original_slice, cmap='gray')\n",
    "            if show_heatmap:\n",
    "                plt.imshow(error_slice_normalized, cmap=cmap, alpha=alpha)\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    interactive_plot = widgets.interactive(update_visualization, slice_index=slice_slider, show_heatmap=heatmap_checkbox)\n",
    "    display(interactive_plot) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract images from the eval_test_gen generator\n",
    "sample_images_test, _ = eval_test_gen[10]\n",
    "sample_image_test = sample_images_test[0, ..., 0]\n",
    "reconstructed_image_test = model.predict(np.expand_dims(sample_image_test, axis=(0, -1)))[0, ..., 0]\n",
    "\n",
    "# Extract images from the other generators\n",
    "sample_images_healthy, _ = healthy_gen[10]\n",
    "sample_image_healthy = sample_images_healthy[0, ..., 0]\n",
    "reconstructed_image_healthy = model.predict(np.expand_dims(sample_image_healthy, axis=(0, -1)))[0, ..., 0]\n",
    "\n",
    "sample_images_mci, _ = mci_gen[10]\n",
    "sample_image_mci = sample_images_mci[0, ..., 0]\n",
    "reconstructed_image_mci = model.predict(np.expand_dims(sample_image_mci, axis=(0, -1)))[0, ..., 0]\n",
    "\n",
    "sample_images_ad, _ = ad_gen[10]\n",
    "sample_image_ad = sample_images_ad[0, ..., 0]\n",
    "reconstructed_image_ad = model.predict(np.expand_dims(sample_image_ad, axis=(0, -1)))[0, ..., 0]\n",
    "\n",
    "images_dict = {\n",
    "    'Test': (sample_image_test, reconstructed_image_test),\n",
    "    'Healthy': (sample_image_healthy, reconstructed_image_healthy),\n",
    "    'MCI': (sample_image_mci, reconstructed_image_mci),\n",
    "    'AD': (sample_image_ad, reconstructed_image_ad),\n",
    "}\n",
    "\n",
    "multi_image_interactive_slice_viewer(images_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
